{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.estimator import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def build_dfp_jobs(jobs):\n",
    "    informations = [job.describe() for job in jobs]\n",
    "    return pd.DataFrame(informations).sort_values(['CreationTime'], ascending=False)\n",
    "\n",
    "def collect_infos_from_output_config(output_config, keyword):\n",
    "    outputs = output_config['Outputs']\n",
    "    for output in outputs:\n",
    "        if keyword in output['OutputName']:\n",
    "            return output\n",
    "    return {}\n",
    "\n",
    "# these functions are just collecting the first jobs that is completed, nothing perfect \n",
    "def collect_output_config_processor(dfp_jobs_processor, prefix):\n",
    "    for idx, row in dfp_jobs_processor[dfp_jobs_processor['ProcessingJobStatus'] == 'Completed'].iterrows():\n",
    "        # Taking of the one of the laste completed execution for the 0_process job\n",
    "        if prefix in row['ProcessingJobName']:\n",
    "            return row['ProcessingOutputConfig']\n",
    "    return ''\n",
    "\n",
    "def collect_output_config_trainer(dfp_jobs_processor, prefix):\n",
    "    # Collect the informations that can be useful for the evaluation and coring features\n",
    "    for idx, row in dfp_jobs_trainer[dfp_jobs_trainer['TrainingJobStatus'] == 'Completed'].iterrows():\n",
    "        # Taking of the one of the laste completed execution for the 0_process job\n",
    "        name_train_job = row['TrainingJobName']\n",
    "        if prefix in name_train_job:\n",
    "            output_config_train_job = row['OutputDataConfig']\n",
    "            return name_train_job, output_config_train_job\n",
    "    \n",
    "    return '', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some region and role for the execution of the jobs\n",
    "region = boto3.session.Session().region_name\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an operator sklearn to process (give some infos on the type of machine, what role and the version of sklearn to use)\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the location of the data to process\n",
    "input_data_ml = f'{os.environ[\"AWS_SAGEMAKER_S3_LOCATION\"]}/data/dataset_ml.csv'\n",
    "input_data_to_score = f'{os.environ[\"AWS_SAGEMAKER_S3_LOCATION\"]}/data/dataset_toscore.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the job to prpcess the data\n",
    "job_name = f'0-process-{datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "\n",
    "# Execute a new job to process the data with the code define in the script\n",
    "sklearn_processor.run(code='jobs/0_process.py',\n",
    "                      inputs=[\n",
    "                          ProcessingInput(# Define the location of the dataset for the ml part, and where it will be stored on the container\n",
    "                              source=input_data_ml,\n",
    "                              destination='/opt/ml/processing/input/ml'),\n",
    "                          ProcessingInput(# Define the location of the dataset for the scoring part, and where it will be stored on the container\n",
    "                              source=input_data_to_score,\n",
    "                              destination='/opt/ml/processing/input/toscore')],\n",
    "                      outputs=[# Define the various outputs of the processing job (train, test and score datasets)\n",
    "                          ProcessingOutput(\n",
    "                              source='/opt/ml/processing/train',\n",
    "                              output_name='train_data'),\n",
    "                          ProcessingOutput(\n",
    "                              source='/opt/ml/processing/test', \n",
    "                              output_name='test_data'),\n",
    "                          ProcessingOutput(\n",
    "                              source='/opt/ml/processing/score',\n",
    "                              output_name='score_data')],\n",
    "                      arguments=['--test_size', '0.21'],# Define some arguments to processing job\n",
    "                      job_name = job_name)# Build an human understandable name for the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pandas dataframe to store the data on the execution of the jobs\n",
    "dfp_jobs_processor = build_dfp_jobs(sklearn_processor.jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_config_process_job = collect_output_config_processor(dfp_jobs_processor, '0-process')\n",
    "output_config_process_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a training job\n",
    "sklearn_trainer = SKLearn(\n",
    "    entry_point='jobs/1_train.py',\n",
    "    train_instance_type=\"ml.m4.xlarge\",\n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model based on the output of the previous job\n",
    "infos_train_data = collect_infos_from_output_config(output_config_process_job, 'train_data')\n",
    "if infos_train_data != {}:\n",
    "    job_name = f'1-train-{datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "    sklearn_trainer.fit(\n",
    "        {'train': infos_train_data['S3Output']['S3Uri']},\n",
    "        job_name = job_name\n",
    "    )\n",
    "else:\n",
    "    print(f'Check the variable output_config_process_job that seems to miss some informations:{output_config_process_job}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_jobs_trainer = build_dfp_jobs(sklearn_trainer.jobs)\n",
    "name_train_job, output_config_train_job = collect_output_config_trainer(dfp_jobs_trainer, '1-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the location fo the model selected\n",
    "model_data_s3_uri = '{}{}/{}'.format(\n",
    "    output_config_train_job['S3OutputPath'],\n",
    "    name_train_job,\n",
    "    'output/model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_test_data = collect_infos_from_output_config(output_config_process_job, 'test_data')\n",
    "\n",
    "job_name = job_name = f'2-evaluate-{datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "sklearn_processor.run(code='jobs/2_evaluate.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                                  source=model_data_s3_uri,\n",
    "                                  destination='/opt/ml/processing/model'),\n",
    "                              ProcessingInput(\n",
    "                                  source=infos_test_data['S3Output']['S3Uri'],\n",
    "                                  destination='/opt/ml/processing/test')],\n",
    "                      outputs=[ProcessingOutput(output_name='evaluation',\n",
    "                                  source='/opt/ml/processing/evaluation')],\n",
    "                      job_name = job_name\n",
    "                     )                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_score_data = collect_infos_from_output_config(output_config_process_job, 'score_data')\n",
    "\n",
    "job_name = job_name = f'3-score-{datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "sklearn_processor.run(code='jobs/3_score.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                                  source=model_data_s3_uri,\n",
    "                                  destination='/opt/ml/processing/model'),\n",
    "                              ProcessingInput(\n",
    "                                  source=infos_score_data['S3Output']['S3Uri'],\n",
    "                                  destination='/opt/ml/processing/score')],\n",
    "                      outputs=[ProcessingOutput(output_name='predictions',\n",
    "                                  source='/opt/ml/processing/predictions')],\n",
    "                      job_name = job_name\n",
    "                     )               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f'Execution {i}')\n",
    "    sklearn_processor.run(code='jobs/0_process.py',\n",
    "                      inputs=[\n",
    "                          ProcessingInput(# Define the location of the dataset for the ml part, and where it will be stored on the container\n",
    "                              source=input_data_ml,\n",
    "                              destination='/opt/ml/processing/input/ml'),\n",
    "                          ProcessingInput(# Define the location of the dataset for the scoring part, and where it will be stored on the container\n",
    "                              source=input_data_to_score,\n",
    "                              destination='/opt/ml/processing/input/toscore')],\n",
    "                      outputs=[# Define the various outputs of the processing job (train, test and score datasets)\n",
    "                          ProcessingOutput(\n",
    "                              source='/opt/ml/processing/train',\n",
    "                              output_name='train_data'),\n",
    "                          ProcessingOutput(\n",
    "                              source='/opt/ml/processing/test', \n",
    "                              output_name='test_data'),\n",
    "                          ProcessingOutput(\n",
    "                              source='/opt/ml/processing/score',\n",
    "                              output_name='score_data')],\n",
    "                      arguments=['--test_size', '0.21'],# Define some arguments to processing job\n",
    "                      job_name = f'0-process-{datetime.utcnow().strftime(\"%Y%m%d\")}-execution{i}')# Build an human understandable name for the job\n",
    "    sklearn_trainer.fit(\n",
    "        {'train': infos_train_data['S3Output']['S3Uri']},\n",
    "        job_name = f'1-train-{datetime.utcnow().strftime(\"%Y%m%d\")}-execution{i}'\n",
    "    )\n",
    "    sklearn_processor.run(code='jobs/2_evaluate.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                                  source=model_data_s3_uri,\n",
    "                                  destination='/opt/ml/processing/model'),\n",
    "                              ProcessingInput(\n",
    "                                  source=infos_test_data['S3Output']['S3Uri'],\n",
    "                                  destination='/opt/ml/processing/test')],\n",
    "                      outputs=[ProcessingOutput(output_name='evaluation',\n",
    "                                  source='/opt/ml/processing/evaluation')],\n",
    "                      job_name = f'2-evaluate-{datetime.utcnow().strftime(\"%Y%m%d\")}-execution{i}')        \n",
    "    sklearn_processor.run(code='jobs/3_score.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                                  source=model_data_s3_uri,\n",
    "                                  destination='/opt/ml/processing/model'),\n",
    "                              ProcessingInput(\n",
    "                                  source=infos_score_data['S3Output']['S3Uri'],\n",
    "                                  destination='/opt/ml/processing/score')],\n",
    "                      outputs=[ProcessingOutput(output_name='predictions',\n",
    "                                  source='/opt/ml/processing/predictions')],\n",
    "                      job_name = f'3-score-{datetime.utcnow().strftime(\"%Y%m%d\")}-execution{i}')               \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_process = build_dfp_jobs(jobs):\n",
    "    informations = [job.describe() for job in jobs]\n",
    "    return pd.DataFrame(informations).sort_values(['CreationTime'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_jobs_processor = build_dfp_jobs(sklearn_processor.jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect some details on the output of the evaluation\n",
    "output_config_evaluate_job = collect_output_config_processor(dfp_jobs_processor, '2-evaluate')\n",
    "infos_evaluation = collect_infos_from_output_config(output_config_evaluate_job, 'evaluation')\n",
    "dfp_evaluation = pd.read_csv(infos_evaluation['S3Output']['S3Uri'] + '/metrics.csv')\n",
    "dfp_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect some details on the output of the scoring\n",
    "output_config_score_job = collect_output_config_processor(dfp_jobs_processor, '3-score')\n",
    "infos_scoring = collect_infos_from_output_config(output_config_score_job, 'predictions')\n",
    "dfp_score = pd.read_csv(infos_scoring['S3Output']['S3Uri'] + '/predictions.csv')\n",
    "dfp_score.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_score_data['S3Output']['S3Uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp_jobs_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
